using JuMP
using Cbc
using DataFrames
using TimeZones
using Dates
using DataStructures
using XLSX

"""
    get_result_dataframe(model_contents,type="",process="",node="",scenario="")

Returns a dataframe containing specific information from the model?

# Arguments
- `model_contents::OrderedDict`: ?
- `type`: ?
- `process`: ?
- `node`: ?
- `scenario`: ?
"""
function get_result_dataframe(model_contents::OrderedDict, input_data::Predicer.InputData,type::String="",process::String="",node::String="",scenario::String="")
    println("Getting results for:")
    tuples = Predicer.create_tuples(input_data)
    temporals = unique(map(x->x[5],tuples["process_tuple"]))
    df = DataFrame(t = temporals)
    vars = model_contents["variable"]
    expr = model_contents["expression"]
    if type == "v_flow"
        v_flow = vars[type]
        tups = unique(map(x->(x[1],x[2],x[3]),filter(x->x[1]==process, tuples["process_tuple"])))
        for tup in tups
            colname = join(tup,"-")
            col_tup = filter(x->x[1:3]==tup && x[4]==scenario, tuples["process_tuple"])
            if !isempty(col_tup)
                df[!, colname] = value.(v_flow[col_tup].data)
            end
        end
    elseif type == "v_reserve"
        v_res = vars[type]
        tups = unique(map(x->(x[1],x[2],x[3],x[5]),filter(x->x[3]==process, tuples["res_potential_tuple"])))
        for tup in tups
            col_name = join(tup,"-")
            col_tup = filter(x->(x[1],x[2],x[3],x[5])==tup && x[6]==scenario, tuples["res_potential_tuple"])
            if !isempty(col_tup)
                df[!, col_name] = value.(v_res[col_tup].data)
            end
        end
    elseif type == "v_res_final"
        v_res = vars[type]
        ress = unique(map(x->x[1],tuples["res_final_tuple"]))
        for r in ress
            col_tup = filter(x->x[1]==r && x[2]==scenario, tuples["res_final_tuple"])
            if !isempty(col_tup)
                df[!, r] = value.(v_res[col_tup].data)
            end
        end

    elseif type == "v_online" || type == "v_start" || type == "v_stop"
        v_bin = vars[type]
        procs = unique(map(x->x[1],tuples["process_tuple"]))
        for p in procs
            col_tup = filter(x->x[1]==p && x[2]==scenario, tuples["proc_online_tuple"])
            if !isempty(col_tup)
                df[!, p] = value.(v_bin[col_tup].data)
            end
        end
    elseif type == "v_state"
        v_state = vars[type]
        col_tup = filter(x->x[1]==node && x[2]==scenario, tuples["node_state_tuple"])
        if !isempty(col_tup)
            df[!, node] = value.(v_state[col_tup].data)
        end
    elseif type == "vq_state_up" || type == "vq_state_dw"
        v_state = vars[type]
        nods = unique(map(x->x[1],tuples["node_balance_tuple"]))
        for n in nods
            col_tup = filter(x->x[1]==n && x[2]==scenario, tuples["node_balance_tuple"])
            if !isempty(col_tup)
                df[!, n] = value.(v_state[col_tup].data)
            end
        end
    elseif type == "v_bid"
        v_bid = expr[type]
        bid_tups = unique(map(x->(x[1],x[3],x[4]),filter(x->x[1]==node && x[3]==scenario,tuples["balance_market_tuple"])))

        dat_vec = []
        for (i,tup) in enumerate(bid_tups)
            push!(dat_vec,value(v_bid[tup]))
        end
        df[!,node] = dat_vec
    elseif type == "v_flow_bal"
        v_bal = vars[type]
        dir = ["up","dw"]
        for d in dir
            tup = filter(x->x[1]==node && x[2]==d && x[3]==scenario, tuples["balance_market_tuple"])
            if !isempty(tup)
                df[!,d] = value.(v_bal[tup].data)
            end
        end
    else
        println("ERROR: incorrect type")
    end
    return df
end
 
"""
    write_bid_matrix(model_contents::OrderedDict, input_data::OrderedDict)

Returns the bid matric generated by the model?
"""
function write_bid_matrix(model_contents::OrderedDict, input_data::Predicer.InputData)
    println("Writing bid matrix...")
    vars = model_contents["variable"]
    v_flow = vars["v_flow"]
    v_bid = model_contents["expression"]["v_bid"]
    if input_data.contains_reserves
        v_res_final = vars["v_res_final"]
    end

    tuples = Predicer.create_tuples(input_data)
    temporals = input_data.temporals.t
    markets = input_data.markets
    scenarios = keys(input_data.scenarios)

    if !isdir(pwd()*"\\results")
        mkdir("results")
    end
    output_path = string(pwd()) * "\\results\\bid_matrix_"*Dates.format(Dates.now(), "yyyy-mm-dd-HH-MM-SS")*".xlsx"
    XLSX.openxlsx(output_path, mode="w") do xf
        for (i,m) in enumerate(keys(markets))
            XLSX.addsheet!(xf, m)
            df = DataFrame(t = temporals)
            for s in scenarios
                p_name = "PRICE-"*s
                v_name = "VOLUME-"*s
                price = map(x->x[2],filter(x->x.scenario==s,markets[m].price.ts_data)[1].series)
                if markets[m].type == "energy"
                    bid_tuple = unique(map(x->(x[1],x[3],x[4]),filter(x->x[1]==markets[m].node && x[3]==s,tuples["balance_market_tuple"])))
                    volume = []
                    for tup in bid_tuple
                        push!(volume,value(v_bid[tup]))
                    end
                    #tup_b = filter(x->x[2]==m && x[4]==s,tuples["process_tuple"])
                    #tup_s = filter(x->x[3]==m && x[4]==s,tuples["process_tuple"])
                    #volume = value.(v_flow[tup_s].data)-value.(v_flow[tup_b].data)
                else
                    if input_data.contains_reserves
                        tup = filter(x->x[1]==m && x[2]==s,tuples["res_final_tuple"])
                        volume = value.(v_res_final[tup].data)
                    end
                end
                df[!,p_name] = price
                df[!,v_name] = volume
            end
            XLSX.writetable!(xf[i+1], collect(eachcol(df)), names(df))
        end
    end
end

function resolve_delays(input_data::Predicer.InputData)
    processes = input_data.processes
    processes_to_add = []
    nodes_to_add = []
    highest_delay = 0
    for p in keys(processes)
        delay_topos = filter(t -> t.delay > 0, processes[p].topos)
        if !isempty(delay_topos)
            for topo in delay_topos
                highest_delay = max(topo.delay, highest_delay)
                if processes[p].conversion == 2 # transfer process
                    Predicer.add_delay(processes[p], topo.delay)
                    topo.delay = 0
                elseif processes[p].conversion == 1 # unit based process
                    # create node
                    delay_n_name = "delayNode_" * processes[p].name * "_" * topo.source * "_to_" * topo.sink
                    dn = Node(delay_n_name)
                    push!(nodes_to_add, dn)

                    # create transfer process
                    delay_p_name = "delayProcess_" * processes[p].name * "_" * topo.source * "_to_" * topo.sink
                    dp = TransferProcess(delay_p_name, topo.delay)
                    add_eff(dp, 1.0)
                    add_load_limits(dp, 0.0, 1.0)

                    # add topos to new delay/transport process
                    # - if topo is a sink of p, add the delay node after p
                    # - if topo is a source of p, add the delay node before p
                    if topo.source == processes[p].name # The topo is a sink, as it goes from the process, 
                        add_topology(dp, Topology(delay_n_name, topo.sink, topo.capacity, 0.0, 1.0, 1.0, 0.0))

                    elseif topo.sink == processes[p].name
                        add_topology(dp, Topology(topo.source, delay_n_name, topo.capacity, 0.0, 1.0, 1.0, 0.0))
                    end
                    push!(processes_to_add, dp)

                    # change p topos depending on if it is a so or si. 
                    # - delay node as so if topo is a so
                    # - delay node as si if topo is a sink
                    if topo.source == processes[p].name
                        for t in processes[p].topos
                            if t == topo
                                t.sink = delay_n_name
                                t.delay = 0
                            end
                        end
                    else
                        for t in processes[p].topos
                            if t == topo
                                t.source = delay_n_name
                                t.delay = 0
                            end
                        end
                    end
                    # manage "history" of original nodes.
                end
            end
        end
    end
    for p in processes_to_add
        input_data.processes[p.name] = p
    end
    for n in nodes_to_add
        input_data.nodes[n.name] = n
    end
    return input_data
end